# I Introduction
“If I have seen further, it is by standing on the shoulders of giants.” 

<p style="text-align:right">— Isaac Newton</p>

&emsp;&emsp;Robots are designed to extend human capabilities, assisting in tasks that are dangerous, repetitive, or demand high precision, thereby enhancing productivity across diverse applications. Achieving such capabilities requires agents to move beyond reactive control and the mere replication of observed states, instead developing the ability to model, reason about, and predict environmental dynamics. In this context, world models have emerged as powerful internal representations that enable robots to anticipate future outcomes, support effective decision-making, and ultimately act intelligently in the real world. Richens et al. [1] argue that any agent capable of generalizing to solve multi-step tasks must implicitly learn a predictive model of its environment, e.g., a world model. 

&emsp;&emsp;The concept of “world models” in computer science dates back to the 1960s [2], and numerous methods have since been proposed as steps toward more capable models [3], [4], [5], [6], [7], [8], [9], [10], although not all of these works explicitly identify themselves as world models. For example, Wang et al. [9], [10], [5], [6], [7], [8] leverage video generation models as a form of world models, which encode extensive world knowledge from large-scale training data and can predict future states based current observations and/or actions. LeCun et al. [11], [12], [13], [14], [15] emphasizes modeling abstract world state representations, while Zitkovich et al. [16], [17], [18] utilize vision-language-action models (VLA) models that do not explicitly generate future states. The scope of existing methods varies from 2D scene prediction to 4D world modeling [19], [20], [21], [22], [23], [24], reflecting different understandings of what it means to model the world. The observation viewpoint of the world includes both third-person (exocentric) [21], [25], [26] and first-person (egocentric) [27], [28] perspectives. 

&emsp;&emsp;World models play a critical role in robotic learning in two ways. They allow robots to improve autonomous policies by simulating multiple action proposals and selecting the optimal one for execution [29], [12], [13], [14], [30], [21]. They also support scalable policy training and evaluation by generating realistic rollouts and physical interactions, providing an efficient alternative to collecting data in the real world. [16], [31], [32], [33], [34], [35]. From a functional standpoint, current approaches range from single-purpose models, such as those designed for visual planning [30], [36], future-scene generation [37], [33], [38], or action prediction [39], to more integrated systems that couple multiple abilities within a unified framework [40], [27], [41], [42], [43].  

&emsp;&emsp;These variations indicate that the notion of a world model remains unsettled, with its conceptual, architectural, and functional boundaries not yet clearly defined.  

&emsp;&emsp;Addressing these questions requires standing on the shoulders of prior contributions, carefully analyzing existing methodologies to gain inspiration for elucidating the boundaries of world models. In this survey, rather than hastily defining what constitutes a world model, we provide a comprehensive review of the literature, highlighting their core principles, architectures, and functional roles in enabling intelligent robotic systems. We extend the scope beyond works explicitly labeled as world models, examining their core principles and outlining pathways for constructing practical models that can drive the development of general and adaptive robotic agents. 

&emsp;&emsp;This survey is organized around a set of guiding questions designed to provoke thought and provide inspiration. Readers can explore the survey with these questions in mind, using them to provoke thought, gain inspiration, and reflect on the challenges and opportunities in developing world models for robotic manipulation.

* What is the world model and its conceptual, architectural, and functional boundaries? • How should the world be sensed and presented? 
* What level of model fidelity and coverage is required to reliably support robotic tasks? 
* Is it necessary to learn a world model, given the complexity, resource demands, and potential challenges involved? 
* How far are current world models from fully realized world models? 
* Is human cognition [44], [45] the ultimate goal for world models?

&emsp;&emsp;The main contributions of this survey are as follows:  

* **Comprehensive taxonomy of world model architectures. **We provide a systematic categorization of existing designs, including latent space modeling methods, video generation-based models, direct projection based methods and other emerging structures. 
* **Functional analysis. **We discuss the diverse roles of world models in robotics, including robotic learning, evaluation, and planning, highlighting their contribution to autonomous control.  
* **Capability framework.** We analyze the essential abilities that a world model should possess, such as perception, prediction, imagination, and interaction, aiming to clarify what constitutes a generalizable and capable world model. 
* **Challenges and future directions.** We summarize key challenges, including scalability, physical awareness, and generalization, and discuss potential research directions and solutions toward building practical, real-world models.

**Related Surveys.** Our survey differs substantially from existing reviews. Several surveys have examined world models in robotics, but most focus on specific aspects and provide limited conceptual analysis. For example, Yu et al. [46] emphasize video generation, Kong et al. [47] cover 3D/4D world modeling, Ai et al. [48] study dynamics learning, and Lin et al. [49] address physics cognition. Long et al. [50] review architectures and functional roles of world models, whereas Zhu et al. [51], [52], [53] primarily compile representative works. While these surveys provide valuable overviews, they offer limited discussion of the essential characteristics and functional requirements of comprehensive world models for embodied agents. In contrast, our survey presents a holistic, problem-centered perspective, highlighting key challenges, solution strategies, and future directions for world modeling in robotics. 

**Paper Organization. **The remainder of this paper is organized as follows. Section II introduces the conceptual foundations of world models. Section III provides an overview of current world models, including their learning paradigms, structural designs, representations of the world, and task scopes. Sections IV and V describe the key functions of existing world models and summarize the principal techniques and challenges, respectively. Section VII reviews the major training resources used in world-model research. Section VI then summarizes the fundamental components and capabilities of world models based on this review, followed by Section VIII, which presents conclusions and outlines future research directions. Although this may occasionally lead to some repetition, certain key ideas are revisited throughout the paper to aid understanding and reinforce their conceptual connections.