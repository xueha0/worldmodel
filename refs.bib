@article{yang2024physical,
  title={Physical informed driving world model},
  author={Yang, Zhuoran and Guo, Xi and Ding, Chenjing and Wang, Chiyu and Wu, Wei},
  journal={arXiv preprint arXiv:2412.08410},
  year={2024}
}
@inproceedings{wen2024panacea,
  title={Panacea: Panoramic and controllable video generation for autonomous driving},
  author={Wen, Yuqing and Zhao, Yucheng and Liu, Yingfei and Jia, Fan and Wang, Yanhui and Luo, Chong and Zhang, Chi and Wang, Tiancai and Sun, Xiaoyan and Zhang, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6902--6912},
  year={2024}
}
@inproceedings{heusel2017gans,
  title={GANs trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={6629--6640},
  year={2017}
}
@article{unterthiner2018towards,
  title={Towards accurate generative models of video: A new metric \& challenges},
  author={Unterthiner, Thomas and Van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}
@inproceedings{kang2025far,
  title={How Far Is Video Generation from World Model: A Physical Law Perspective},
  author={Kang, Bingyi and Yue, Yang and Lu, Rui and Lin, Zhijie and Zhao, Yang and Wang, Kaixin and Huang, Gao and Feng, Jiashi},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@inproceedings{mengtowards,
  title={Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation},
  author={Meng, Fanqing and Liao, Jiaqi and Tan, Xinyu and Lu, Quanfeng and Shao, Wenqi and Zhang, Kaipeng and Cheng, Yu and Li, Dianqi and Luo, Ping},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@article{richens2024robust,
  title={Robust agents learn causal world models},
  author={Richens, Jonathan and Everitt, Tom},
  journal={arXiv preprint arXiv:2402.10877},
  year={2024}
}
@inproceedings{wang2022causal,
  title={Causal Dynamics Learning for Task-Independent State Abstraction},
  author={Wang, Zizhao and Xiao, Xuesu and Xu, Zifan and Zhu, Yuke and Stone, Peter},
  booktitle={International Conference on Machine Learning},
  pages={23151--23180},
  year={2022}
}
@article{wang2025embodiedreamer,
  title={EmbodieDreamer: Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling},
  author={Wang, Boyuan and Meng, Xinpan and Wang, Xiaofeng and Zhu, Zheng and Ye, Angen and Wang, Yang and Yang, Zhiqin and Ni, Chaojun and Huang, Guan and Wang, Xingang},
  journal={arXiv preprint arXiv:2507.05198},
  year={2025}
}
@inproceedings{barcellona2025dream,
  title={Dream to Manipulate: Compositional World Models Empowering Robot Imitation Learning with Imagination},
  author={Barcellona, Leonardo and Zadaianchuk, Andrii and Allegro, Davide and Papa, Samuele and Ghidoni, Stefano and Gavves, Efstratios},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{kerbl20233d,
  title={3D Gaussian splatting for real-time radiance field rendering.},
  author={Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
  journal={ACM Trans. Graph.},
  volume={42},
  number={4},
  pages={139--1},
  year={2023}
}
@inproceedings{wu2023daydreamer,
  title={Daydreamer: World models for physical robot learning},
  author={Wu, Philipp and Escontrela, Alejandro and Hafner, Danijar and Abbeel, Pieter and Goldberg, Ken},
  booktitle={Conference on robot learning},
  pages={2226--2240},
  year={2023},
  organization={PMLR}
}
@article{lecun2022path,
  title={A path towards autonomous machine intelligence},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  pages={1--62},
  year={2022}
}
@article{ferraro2025focus,
  title={FOCUS: object-centric world models for robotic manipulation},
  author={Ferraro, Stefano and Mazzaglia, Pietro and Verbelen, Tim and Dhoedt, Bart},
  journal={Frontiers in Neurorobotics},
  volume={19},
  pages={1585386},
  year={2025},
  publisher={Frontiers Media SA}
}
@article{liao2025genie,
  title={Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation},
  author={Liao, Yue and Zhou, Pengfei and Huang, Siyuan and Yang, Donglin and Chen, Shengcong and Jiang, Yuxin and Hu, Yue and Cai, Jingbin and Liu, Si and Luo, Jianlan},
  journal={arXiv preprint arXiv:2508.05635},
  year={2025}
}
@article{agarwal2025cosmos,
  title={Cosmos world foundation model platform for physical ai},
  author={Agarwal, Niket and Ali, Arslan and Bala, Maciej and Balaji, Yogesh and Barker, Erik and Cai, Tiffany and Chattopadhyay, Prithvijit and Chen, Yongxin and Cui, Yin and Ding, Yifan},
  journal={arXiv preprint arXiv:2501.03575},
  year={2025}
}
@article{he2025pre,
  title={Pre-trained video generative models as world simulators},
  author={He, Haoran and Zhang, Yang and Lin, Liang and Xu, Zhongwen and Pan, Ling},
  journal={arXiv preprint arXiv:2502.07825},
  year={2025}
}
@inproceedings{black2024zero,
  title={Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models},
  author={Black, Kevin and Nakamoto, Mitsuhiko and Atreya, Pranav and Walke, Homer Rich and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@inproceedings{liu2023flow,
  title={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  booktitle={The Eleventh International Conference on Learning Representations (ICLR)},
  year={2023}
}
@article{zheng2024open,
  title={Open-sora: Democratizing efficient video production for all},
  author={Zheng, Zangwei and Peng, Xiangyu and Yang, Tianji and Shen, Chenhui and Li, Shenggui and Liu, Hongxin and Zhou, Yukun and Li, Tianyi and You, Yang},
  journal={arXiv preprint arXiv:2412.20404},
  year={2024}
}

@article{wu2024ivideogpt,
  title={ivideogpt: Interactive videogpts are scalable world models},
  author={Wu, Jialong and Yin, Shaofeng and Feng, Ningya and He, Xu and Li, Dong and Hao, Jianye and Long, Mingsheng},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={68082--68119},
  year={2024}
}
@inproceedings{o2024open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models: Open x-embodiment collaboration 0},
  author={Oâ€™Neill, Abby and Rehman, Abdul and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and Jain, Ajinkya},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6892--6903},
  year={2024},
  organization={IEEE}
}
@article{ha2018world,
  title={World Models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1803.10122},
  year={2018}
}
@article{quevedo2025evaluating,
  title={Evaluating Robot Policies in a World Model},
  author={Quevedo, Julian and Liang, Percy and Yang, Sherry},
  journal={arXiv preprint arXiv:2506.00613},
  year={2025}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@inproceedings{erez2015simulation,
  title={Simulation tools for model-based robotics: Comparison of bullet, havok, mujoco, ode and physx},
  author={Erez, Tom and Tassa, Yuval and Todorov, Emanuel},
  booktitle={2015 IEEE international conference on robotics and automation (ICRA)},
  pages={4397--4404},
  year={2015},
  organization={IEEE}
}
@misc{tedrake2019drake,
  title={Drake: Model-based design and verification for robotics},
  author={Tedrake, Russ},
  year={2019}
}
@article{sunderhauf2018limits,
  title={The limits and potentials of deep learning for robotics},
  author={S{\"u}nderhauf, Niko and Brock, Oliver and Scheirer, Walter and Hadsell, Raia and Fox, Dieter and Leitner, J{\"u}rgen and Upcroft, Ben and Abbeel, Pieter and Burgard, Wolfram and Milford, Michael},
  journal={The International journal of robotics research},
  volume={37},
  number={4-5},
  pages={405--420},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{afzal2020study,
  title={A study on the challenges of using robotics simulators for testing},
  author={Afzal, Afsoon and Katz, Deborah S and Goues, Claire Le and Timperley, Christopher S},
  journal={arXiv preprint arXiv:2004.07368},
  year={2020}
}
@article{choi2021use,
  title={On the use of simulation in robotics: Opportunities, challenges, and suggestions for moving forward},
  author={Choi, HeeSun and Crump, Cindy and Duriez, Christian and Elmquist, Asher and Hager, Gregory and Han, David and Hearl, Frank and Hodgins, Jessica and Jain, Abhinandan and Leve, Frederick},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={1},
  pages={e1907856118},
  year={2021},
  publisher={National Academy of Sciences}
}
@inproceedings{zhao2020sim,
  title={Sim-to-real transfer in deep reinforcement learning for robotics: a survey},
  author={Zhao, Wenshuai and Queralta, Jorge Pe{\~n}a and Westerlund, Tomi},
  booktitle={2020 IEEE symposium series on computational intelligence (SSCI)},
  pages={737--744},
  year={2020},
  organization={IEEE}
}
@article{dulac2019challenges,
  title={Challenges of real-world reinforcement learning},
  author={Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
  journal={arXiv preprint arXiv:1904.12901},
  year={2019}
}
@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{gao2024flip,
  title={FLIP: Flow-Centric Generative Planning as General-Purpose Manipulation World Model},
  author={Gao, Chongkai and Zhang, Haozhuo and Xu, Zhixuan and Zhehao, Cai and Shao, Lin},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2024}
}
@article{liu2023libero,
  title={Libero: Benchmarking knowledge transfer for lifelong robot learning},
  author={Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={44776--44791},
  year={2023}
}
@inproceedings{hore2010image,
  title={Image quality metrics: PSNR vs. SSIM},
  author={Hore, Alain and Ziou, Djemel},
  booktitle={2010 20th international conference on pattern recognition},
  pages={2366--2369},
  year={2010},
  organization={IEEE}
}
@article{schmidhuber2015learning,
  title={On learning to think: Algorithmic information theory for novel combinations of reinforcement learning controllers and recurrent neural world models},
  author={Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1511.09249},
  year={2015}
}
@article{ali2025humanoid,
  title={Humanoid World Models: Open World Foundation Models for Humanoid Robotics},
  author={Ali, Muhammad Qasim and Sridhar, Aditya and Matiana, Shahbuland and Wong, Alex and Al-Sharman, Mohammad},
  journal={arXiv preprint arXiv:2506.01182},
  year={2025}
}
@article{guo2025flowdreamer,
  title={FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation},
  author={Guo, Jun and Ma, Xiaojian and Wang, Yikai and Yang, Min and Liu, Huaping and Li, Qing},
  journal={arXiv preprint arXiv:2505.10075},
  year={2025}
}
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@inproceedings{hafner2021mastering,
  title={Mastering Atari with Discrete World Models},
  author={Hafner, Danijar and Lillicrap, Timothy P and Norouzi, Mohammad and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2025}
}
@article{chen2025learning,
  title={Learning World Models for Interactive Video Generation},
  author={Chen, Taiye and Hu, Xun and Ding, Zihan and Jin, Chi},
  journal={arXiv preprint arXiv:2505.21996},
  year={2025}
}
@article{lu2025gwm,
  title={GWM: Towards Scalable Gaussian World Models for Robotic Manipulation},
  author={Lu, Guanxing and Jia, Baoxiong and Li, Puhao and Chen, Yixin and Wang, Ziwei and Tang, Yansong and Huang, Siyuan},
  journal={arXiv preprint arXiv:2508.17600},
  year={2025}
}
@article{zhi20253dflowaction,
  title={3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model},
  author={Zhi, Hongyan and Chen, Peihao and Zhou, Siyuan and Dong, Yubo and Wu, Quanxi and Han, Lei and Tan, Mingkui},
  journal={arXiv preprint arXiv:2506.06199},
  year={2025}
}
@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}
@article{nasiriany2024robocasa,
  title={Robocasa: Large-scale simulation of everyday tasks for generalist robots},
  author={Nasiriany, Soroush and Maddukuri, Abhiram and Zhang, Lance and Parikh, Adeet and Lo, Aaron and Joshi, Abhishek and Mandlekar, Ajay and Zhu, Yuke},
  journal={arXiv preprint arXiv:2406.02523},
  year={2024}
}

@inproceedings{guo2024animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  booktitle={International Conference on Learning Representations},
  year={2024}
}
@article{cen2025worldvla,
  title={WorldVLA: Towards Autoregressive Action World Model},
  author={Cen, Jun and Yu, Chaohui and Yuan, Hangjie and Jiang, Yuming and Huang, Siteng and Guo, Jiayan and Li, Xin and Song, Yibing and Luo, Hao and Wang, Fan},
  journal={arXiv preprint arXiv:2506.21539},
  year={2025}
}
@article{zhang2025dreamvla,
  title={DreamVLA: a vision-language-action model dreamed with comprehensive world knowledge},
  author={Zhang, Wenyao and Liu, Hongsi and Qi, Zekun and Wang, Yunnan and Yu, Xinqiang and Zhang, Jiazhao and Dong, Runpei and He, Jiawei and Wang, He and Zhang, Zhizheng},
  journal={arXiv preprint arXiv:2507.04447},
  year={2025}
}
@article{xiang2024pandora,
  title={Pandora: Towards general world model with natural language actions and video states},
  author={Xiang, Jiannan and Liu, Guangyi and Gu, Yi and Gao, Qiyue and Ning, Yuting and Zha, Yuheng and Feng, Zeyu and Tao, Tianhua and Hao, Shibo and Shi, Yemin},
  journal={arXiv preprint arXiv:2406.09455},
  year={2024}
}
@article{song2025physical,
  title={Physical Autoregressive Model for Robotic Manipulation without Action Pretraining},
  author={Song, Zijian and Qin, Sihan and Chen, Tianshui and Lin, Liang and Wang, Guangrun},
  journal={arXiv preprint arXiv:2508.09822},
  year={2025}
}
@inproceedings{deng2025autoregressive,
  title={Autoregressive Video Generation without Vector Quantization},
  author={Deng, Haoge and Pan, Ting and Diao, Haiwen and Luo, Zhengxiong and Cui, Yufeng and Lu, Huchuan and Shan, Shiguang and Qi, Yonggang and Wang, Xinlong},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{javaheripi2023phi,
  title={Phi-2: The surprising power of small language models},
  author={Javaheripi, Mojan and Bubeck, S{\'e}bastien and Abdin, Marah and Aneja, Jyoti and Bubeck, Sebastien and Mendes, Caio C{\'e}sar Teodoro and Chen, Weizhu and Del Giorno, Allie and Eldan, Ronen and Gopi, Sivakanth},
  journal={Microsoft Research Blog},
  volume={1},
  number={3},
  pages={3},
  year={2023}
}

@article{bjorck2025gr00t,
  title={Gr00t n1: An open foundation model for generalist humanoid robots},
  author={Bjorck, Johan and Casta{\~n}eda, Fernando and Cherniadev, Nikita and Da, Xingye and Ding, Runyu and Fan, Linxi and Fang, Yu and Fox, Dieter and Hu, Fengyuan and Huang, Spencer},
  journal={arXiv preprint arXiv:2503.14734},
  year={2025}
}
@inproceedings{lipman2023flow,
  title={Flow Matching for Generative Modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matthew},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@book{kahneman2011thinking,
  title={Thinking, fast and slow},
  author={Kahneman, Daniel},
  year={2011},
  publisher={macmillan}
}
@article{jang2025dreamgen,
  title={DreamGen: Unlocking Generalization in Robot Learning through Video World Models},
  author={Jang, Joel and Ye, Seonghyeon and Lin, Zongyu and Xiang, Jiannan and Bjorck, Johan and Fang, Yu and Hu, Fengyuan and Huang, Spencer and Kundalia, Kaushil and Lin, Yen-Chen},
  journal={arXiv preprint arXiv:2505.12705},
  year={2025}
}
@inproceedings{zhou2024robodreamer,
  title={RoboDreamer: Learning Compositional World Models for Robot Imagination},
  author={Zhou, Siyuan and Du, Yilun and Chen, Jiaben and Li, Yandong and Yeung, Dit-Yan and Gan, Chuang},
  booktitle={International Conference on Machine Learning},
  pages={61885--61896},
  year={2024},
  organization={PMLR}
}
@article{azzolini2025cosmos,
  title={Cosmos-reason1: From physical common sense to embodied reasoning},
  author={Azzolini, Alisson and Bai, Junjie and Brandon, Hannah and Cao, Jiaxin and Chattopadhyay, Prithvijit and Chen, Huayu and Chu, Jinju and Cui, Yin and Diamond, Jenna and Ding, Yifan},
  journal={arXiv preprint arXiv:2503.15558},
  year={2025}
}

@inproceedings{kitaev2019multilingual,
  title={Multilingual Constituency Parsing with Self-Attention and Pre-Training},
  author={Kitaev, Nikita and Cao, Steven and Klein, Dan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3499--3505},
  year={2019}
}
@article{li2025manipdreamer,
  title={ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance},
  author={Li, Ying and Wei, Xiaobao and Chi, Xiaowei and Li, Yuming and Zhao, Zhongyu and Wang, Hao and Ma, Ningning and Lu, Ming and Zhang, Shanghang},
  journal={arXiv preprint arXiv:2504.16464},
  year={2025}
}
@article{liu2025robotransfer,
  title={RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer},
  author={Liu, Liu and Wang, Xiaofeng and Zhao, Guosheng and Li, Keyu and Qin, Wenkang and Qiu, Jiaxiong and Zhu, Zheng and Huang, Guan and Su, Zhizhong},
  journal={arXiv preprint arXiv:2505.23171},
  year={2025}
}

@inproceedings{wang2025language,
  title={This\&that: Language-gesture controlled video generation for robot planning},
  author={Wang, Boyang and Sridhar, Nikhil and Feng, Chao and Van der Merwe, Mark and Fishman, Adam and Fazeli, Nima and Park, Jeong Joon},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={12842--12849},
  year={2025},
  organization={IEEE}
}
@inproceedings{sennrich2016neural,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1715--1725},
  year={2016}
}
@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}
@inproceedings{venkataramanan2024imagenet,
  title={Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video},
  author={Venkataramanan, Shashanka and Rizve, Mamshad Nayeem and Carreira, Jo{\~a}o and Asano, Yuki and Avrithis, Yannis},
  booktitle={ICLR 2024-Twelfth International Conference on Learning Representations},
  pages={1--21},
  year={2024}
}
@inproceedings{grauman2024ego,
  title={Ego-exo4d: Understanding skilled human activity from first-and third-person perspectives},
  author={Grauman, Kristen and Westbury, Andrew and Torresani, Lorenzo and Kitani, Kris and Malik, Jitendra and Afouras, Triantafyllos and Ashutosh, Kumar and Baiyya, Vijay and Bansal, Siddhant and Boote, Bikram},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19383--19400},
  year={2024}
}

@article{yang2023learning,
  title={Learning interactive real-world simulators},
  author={Yang, Mengjiao and Du, Yilun and Ghasemipour, Kamyar and Tompson, Jonathan and Schuurmans, Dale and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2310.06114},
  volume={1},
  number={2},
  pages={6},
  year={2023}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{ramakrishnan22021habitat,
  title={Habitat-Matterport 3D Dataset (HM3D): 1000 Large-scale 3D Environments for Embodied AI},
  author={Ramakrishnan, Santhosh Kumar and Gokaslan, Aaron and Wijmans, Erik and Maksymets, Oleksandr and Clegg, Alexander and Turner, John M and Undersander, Eric and Galuba, Wojciech and Westbury, Andrew and Chang, Angel X},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}
@article{lynch2023interactive,
  title={Interactive language: Talking to robots in real time},
  author={Lynch, Corey and Wahid, Ayzaan and Tompson, Jonathan and Ding, Tianli and Betker, James and Baruch, Robert and Armstrong, Travis and Florence, Pete},
  journal={IEEE Robotics and Automation Letters},
  year={2023},
  publisher={IEEE}
}
@article{ebert2021bridge,
  title={Bridge data: Boosting generalization of robotic skills with cross-domain datasets},
  author={Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.13396},
  year={2021}
}
@inproceedings{zitkovich2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and Xu, Peng and Xiao, Ted and Xia, Fei and Wu, Jialin and Wohlhart, Paul and Welker, Stefan and Wahid, Ayzaan},
  booktitle={Conference on Robot Learning},
  pages={2165--2183},
  year={2023},
  organization={PMLR}
}
@article{heusel2017gans-1,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{black2024pi_0,
  title={$\pi_0$: A Vision-Language-Action Flow Model for General Robot Control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}
@article{cheang2025gr,
  title={Gr-3 technical report},
  author={Cheang, Chilam and Chen, Sijin and Cui, Zhongren and Hu, Yingdong and Huang, Liqun and Kong, Tao and Li, Hang and Li, Yifeng and Liu, Yuxiao and Ma, Xiao},
  journal={arXiv preprint arXiv:2507.15493},
  year={2025}
}
@article{intelligence2025pi_,
  title={$\pi_{0.5} $: a Vision-Language-Action Model with Open-World Generalization},
  author={Black, Kevin and Brown, Noah and Darpinian, James and Dhabalia, Karan and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo},
  journal={arXiv preprint arXiv:2504.16054},
  year={2025}
}

@inproceedings{unterthiner2019fvd,
  title={FVD: A new metric for video generation},
  author={Unterthiner, Thomas and Van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\"e}l and Michalski, Marcin and Gelly, Sylvain},
  booktitle={ICLR 2022 Workshop: Deep Generative Models for Highly Structured Data},
  year={2017}
}
@inproceedings{hessel2021clipscore,
  title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7514--7528},
  year={2021}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{bruce2024genie,
  title={Genie: generative interactive environments},
  author={Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={4603--4623},
  year={2024}
}
@inproceedings{wu2024unleashing,
  title={Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation},
  author={Wu, Hongtao and Jing, Ya and Cheang, Chilam and Chen, Guangzeng and Xu, Jiafeng and Li, Xinghang and Liu, Minghuan and Li, Hang and Kong, Tao},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}
@article{guo2024prediction,
  title={Prediction with action: Visual policy learning via joint denoising process},
  author={Guo, Yanjiang and Hu, Yucheng and Zhang, Jianke and Wang, Yen-Jen and Chen, Xiaoyu and Lu, Chaochao and Chen, Jianyu},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={112386--112410},
  year={2024}
}

@article{cheang2024gr,
  title={Gr-2: A generative video-language-action model with web-scale knowledge for robot manipulation},
  author={Cheang, Chi-Lam and Chen, Guangzeng and Jing, Ya and Kong, Tao and Li, Hang and Li, Yifeng and Liu, Yuxiao and Wu, Hongtao and Xu, Jiafeng and Yang, Yichu},
  journal={arXiv preprint arXiv:2410.06158},
  year={2024}
}
@article{yang2025roboenvision,
  title={RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation},
  author={Yang, Liudi and Bai, Yang and Eskandar, George and Shen, Fengyi and Altillawi, Mohammad and Chen, Dong and Majumder, Soumajit and Liu, Ziyuan and Kutyniok, Gitta and Valada, Abhinav},
  journal={arXiv preprint arXiv:2506.22007},
  year={2025}
}
@article{Ye2025GigaBrain,
  title={GigaBrain-0: A World Model-Powered Vision-Language-Action Model},
  author={Angen, Ye},
  journal={arXiv:2510.19430},
  year={2025}
}
@inproceedings{liu2025rdt,
  title={RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@inproceedings{ko2024learning,
  title={Learning to Act from Actionless Videos through Dense Correspondences},
  author={Ko, Po-Chen and Mao, Jiayuan and Du, Yilun and Sun, Shao-Hua and Tenenbaum, Joshua B},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}
@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PmLR}
}
@inproceedings{xu2022gmflow,
  title={Gmflow: Learning optical flow via global matching},
  author={Xu, Haofei and Zhang, Jing and Cai, Jianfei and Rezatofighi, Hamid and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8121--8130},
  year={2022}
}

@inproceedings{zhang2025combo,
  title={COMBO: Compositional World Models for Embodied Multi-Agent Cooperation},
  author={Zhang, Hongxin and Wang, Zeyuan and Lyu, Qiushi and Zhang, Zheyuan and Chen, Sunli and Shu, Tianmin and Dariush, Behzad and Lee, Kwonjoon and Du, Yilun and Gan, Chuang},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@inproceedings{gao2025adaworld,
  title={AdaWorld: Learning Adaptable World Models with Latent Actions},
  author={Gao, Shenyuan and Zhou, Siyuan and Du, Yilun and Zhang, Jun and Gan, Chuang},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@article{zhen2025tesseract,
  title={TesserAct: learning 4D embodied world models},
  author={Zhen, Haoyu and Sun, Qiao and Zhang, Hongxin and Li, Junyan and Zhou, Siyuan and Du, Yilun and Gan, Chuang},
  journal={arXiv preprint arXiv:2504.20995},
  year={2025}
}
@article{james2020rlbench,
  title={Rlbench: The robot learning benchmark \& learning environment},
  author={James, Stephen and Ma, Zicong and Arrojo, David Rovick and Davison, Andrew J},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={3019--3026},
  year={2020},
  publisher={IEEE}
}
@article{brooks2024video,
  title={Video generation models as world simulators},
  author={Brooks, Tim and Peebles, Bill and Holmes, Connor and DePue, Will and Guo, Yufei and Jing, Li and Schnurr, David and Taylor, Joe and Luhman, Troy and Luhman, Eric},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={1},
  year={2024}
}
@article{wen2024vidman,
  title={Vidman: Exploiting implicit dynamics from video diffusion model for effective robot manipulation},
  author={Wen, Youpeng and Lin, Junfan and Zhu, Yi and Han, Jianhua and Xu, Hang and Zhao, Shen and Liang, Xiaodan},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={41051--41075},
  year={2024}
}
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}
@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}
@article{zhang2025up,
  title={UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent},
  author={Zhang, Jianke and Guo, Yanjiang and Hu, Yucheng and Chen, Xiaoyu and Zhu, Xiang and Chen, Jianyu},
  journal={ICML},
  year={2025}
}
@inproceedings{zhao2025cot,
  title={Cot-vla: Visual chain-of-thought reasoning for vision-language-action models},
  author={Zhao, Qingqing and Lu, Yao and Kim, Moo Jin and Fu, Zipeng and Zhang, Zhuoyang and Wu, Yecheng and Li, Zhaoshuo and Ma, Qianli and Han, Song and Finn, Chelsea},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={1702--1713},
  year={2025}
}

@inproceedings{tian2025predictive,
  title={Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation},
  author={Tian, Yang and Yang, Sizhe and Zeng, Jia and Wang, Ping and Lin, Dahua and Dong, Hao and Pang, Jiangmiao},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{zhu2025unified,
  title={Unified world models: Coupling video and action diffusion for pretraining on large robotic datasets},
  author={Zhu, Chuning and Yu, Raymond and Feng, Siyuan and Burchfiel, Benjamin and Shah, Paarth and Gupta, Abhishek},
  journal={arXiv preprint arXiv:2504.02792},
  year={2025}
}
@article{oquab2024dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin},
  journal={Transactions on Machine Learning Research Journal},
  pages={1--31},
  year={2024}
}
@article{karaev2024cotracker3,
  title={Cotracker3: Simpler and better point tracking by pseudo-labelling real videos},
  author={Karaev, Nikita and Makarov, Iurii and Wang, Jianyuan and Neverova, Natalia and Vedaldi, Andrea and Rupprecht, Christian},
  journal={arXiv preprint arXiv:2410.11831},
  year={2024}
}
@inproceedings{karaev2024cotracker,
  title={Cotracker: It is better to track together},
  author={Karaev, Nikita and Rocco, Ignacio and Graham, Benjamin and Neverova, Natalia and Vedaldi, Andrea and Rupprecht, Christian},
  booktitle={European conference on computer vision},
  pages={18--35},
  year={2024},
  organization={Springer}
}
@inproceedings{yang2024depth,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10371--10381},
  year={2024}
}
@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}

@inproceedings{huang2024embodied,
  title={An embodied generalist agent in 3D world},
  author={Huang, Jiangyong and Yong, Silong and Ma, Xiaojian and Linghu, Xiongkun and Li, Puhao and Wang, Yan and Li, Qing and Zhu, Song-Chun and Jia, Baoxiong and Huang, Siyuan},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={20413--20451},
  year={2024}
}
@inproceedings{hong2024multiply,
  title={Multiply: A multisensory object-centric embodied large language model in 3d world},
  author={Hong, Yining and Zheng, Zishuo and Chen, Peihao and Wang, Yian and Li, Junyan and Gan, Chuang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26406--26416},
  year={2024}
}
@inproceedings{kim2025openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan P and Sanketi, Pannag R and Vuong, Quan},
  booktitle={Conference on Robot Learning},
  pages={2679--2713},
  year={2025},
  organization={PMLR}
}
@article{minsky1975framework,
  title={A framework for representing knowledge},
  author={MINSKY, M},
  journal={The psychology of computer vision},
  pages={211--277},
  year={1975},
  publisher={McGraw-Hill}
}
@inproceedings{zhen20243d,
  title={3D-VLA: a 3D vision-language-action generative world model},
  author={Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={61229--61245},
  year={2024}
}
@article{hong20233d,
  title={3d-llm: Injecting the 3d world into large language models},
  author={Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20482--20494},
  year={2023}
}

@article{zhang2024sf,
  title={Sf-v: Single forward video generation model},
  author={Zhang, Zhixing and Li, Yanyu and Wu, Yushu and Kag, Anil and Skorokhodov, Ivan and Menapace, Willi and Siarohin, Aliaksandr and Cao, Junli and Metaxas, Dimitris and Tulyakov, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={103599--103618},
  year={2024}
}

@inproceedings{gupta2024photorealistic,
  title={Photorealistic video generation with diffusion models},
  author={Gupta, Agrim and Yu, Lijun and Sohn, Kihyuk and Gu, Xiuye and Hahn, Meera and Li, Fei-Fei and Essa, Irfan and Jiang, Lu and Lezama, Jos{\'e}},
  booktitle={European Conference on Computer Vision},
  pages={393--411},
  year={2024},
  organization={Springer}
}

@inproceedings{team2025aether,
  title={Aether: Geometric-aware unified world modeling},
  author={Zhu, Haoyi and Wang, Yifan and Zhou, Jianjun and Chang, Wenzheng and Zhou, Yang and Li, Zizun and Chen, Junyi and Shen, Chunhua and Pang, Jiangmiao},
  booktitle={ICCV},
  year={2025}
}
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{sudhakar2024controlling,
  title={Controlling the world by sleight of hand},
  author={Sudhakar, Sruthi and Liu, Ruoshi and Hoorick, Basile Van and Vondrick, Carl and Zemel, Richard},
  booktitle={European Conference on Computer Vision},
  pages={414--430},
  year={2024},
  organization={Springer}
}
@inproceedings{lu2025genex,
  title={GenEx: Generating an Explorable World},
  author={Lu, TaiMing and Shu, Tianmin and Yuille, Alan and Khashabi, Daniel and Chen, Jieneng},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{du2023video,
  title={Video Language Planning},
  author={Du, Yilun and Yang, Mengjiao and Florence, Pete and Xia, Fei and Wahid, Ayzaan and Ichter, Brian and Sermanet, Pierre and Yu, Tianhe and Abbeel, Pieter and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:2310.10625},
  year={2023}
}
@article{bu2024closed,
  title={Closed-loop visuomotor control with generative expectation for robotic manipulation},
  author={Bu, Qingwen and Zeng, Jia and Chen, Li and Yang, Yanchao and Zhou, Guyue and Yan, Junchi and Luo, Ping and Cui, Heming and Ma, Yi and Li, Hongyang},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={139002--139029},
  year={2024}
}
@inproceedings{souvcek2024genhowto,
  title={Genhowto: Learning to generate actions and state transformations from instructional videos},
  author={Sou{\v{c}}ek, Tom{\'a}{\v{s}} and Damen, Dima and Wray, Michael and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6561--6571},
  year={2024}
}
@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}
@inproceedings{driess2023palm,
  title={PaLM-E: an embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={8469--8488},
  year={2023}
}
@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@article{du2023learning,
  title={Learning universal policies via text-guided video generation},
  author={Du, Yilun and Yang, Sherry and Dai, Bo and Dai, Hanjun and Nachum, Ofir and Tenenbaum, Josh and Schuurmans, Dale and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={9156--9172},
  year={2023}
}
@article{ni2025wonderfree,
  title={WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration},
  author={Ni, Chaojun and Li, Jie and Li, Haoyun and Liu, Hengyu and Wang, Xiaofeng and Zhu, Zheng and Zhao, Guosheng and Wang, Boyuan and Li, Chenxin and Huang, Guan},
  journal={arXiv preprint arXiv:2506.20590},
  year={2025}
}
@inproceedings{sermanet2024robovqa,
  title={Robovqa: Multimodal long-horizon reasoning for robotics},
  author={Sermanet, Pierre and Ding, Tianli and Zhao, Jeffrey and Xia, Fei and Dwibedi, Debidatta and Gopalakrishnan, Keerthana and Chan, Christine and Dulac-Arnold, Gabriel and Maddineni, Sharath and Joshi, Nikhil J},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={645--652},
  year={2024},
  organization={IEEE}
}
@misc{team2023internlm,
  title={Internlm: A multilingual language model with progressively enhanced capabilities},
  author={Team, InternLM},
  year={2023}
}

@article{chen2025egoagent,
  title={EgoAgent: A Joint Predictive Agent Model in Egocentric Worlds},
  author={Chen, Lu and Wang, Yizhou and Tang, Shixiang and Ma, Qianhong and He, Tong and Ouyang, Wanli and Zhou, Xiaowei and Bao, Hujun and Peng, Sida},
  journal={arXiv preprint arXiv:2502.05857},
  year={2025}
}
@inproceedings{miller2016key,
  title={Key-Value Memory Networks for Directly Reading Documents},
  author={Miller, Alexander and Fisch, Adam and Dodge, Jesse and Karimi, Amir-Hossein and Bordes, Antoine and Weston, Jason},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={1400--1409},
  year={2016}
}
@article{baker2022video,
  title={Video pretraining (vpt): Learning to act by watching unlabeled online videos},
  author={Baker, Bowen and Akkaya, Ilge and Zhokov, Peter and Huizinga, Joost and Tang, Jie and Ecoffet, Adrien and Houghton, Brandon and Sampedro, Raul and Clune, Jeff},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24639--24654},
  year={2022}
}

@article{zhou2025learning,
  title={Learning 3D Persistent Embodied World Models},
  author={Zhou, Siyuan and Du, Yilun and Yang, Yuncong and Han, Lei and Chen, Peihao and Yeung, Dit-Yan and Gan, Chuang},
  journal={arXiv preprint arXiv:2505.05495},
  year={2025}
}
@inproceedings{ye2025latent,
  title={Latent Action Pretraining from Videos},
  author={Ye, Seonghyeon and Jang, Joel and Jeon, Byeongguk and Joo, Se June and Yang, Jianwei and Peng, Baolin and Mandlekar, Ajay and Tan, Reuben and Chao, Yu-Wei and Lin, Bill Yuchen},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@inproceedings{ren2025videoworld,
  title={Videoworld: Exploring knowledge learning from unlabeled videos},
  author={Ren, Zhongwei and Wei, Yunchao and Guo, Xun and Zhao, Yao and Kang, Bingyi and Feng, Jiashi and Jin, Xiaojie},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={29029--29039},
  year={2025}
}
@inproceedings{mentzer2024finite,
  title={Finite Scalar Quantization: VQ-VAE Made Simple},
  author={Mentzer, Fabian and Minnen, David and Agustsson, Eirikur and Tschannen, Michael},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2025}
}
@inproceedings{zheng2025universal,
  title={Universal actions for enhanced embodied foundation models},
  author={Zheng, Jinliang and Li, Jianxiong and Liu, Dongxiu and Zheng, Yinan and Wang, Zhihao and Ou, Zhonghong and Liu, Yu and Liu, Jingjing and Zhang, Ya-Qin and Zhan, Xianyuan},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={22508--22519},
  year={2025}
}
@inproceedings{wen2025diffusionvla,
  title={DiffusionVLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression},
  author={Wen, Junjie and Zhu, Yichen and Zhu, Minjie and Tang, Zhibin and Li, Jinming and Zhou, Zhongyi and Liu, Xiaoyu and Shen, Chaomin and Peng, Yaxin and Feng, Feifei},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@article{huang2025enerverse,
  title={Enerverse: Envisioning embodied future space for robotics manipulation},
  author={Huang, Siyuan and Chen, Liliang and Zhou, Pengfei and Chen, Shengcong and Jiang, Zhengkai and Hu, Yue and Liao, Yue and Gao, Peng and Li, Hongsheng and Yao, Maoqing},
  journal={arXiv preprint arXiv:2501.01895},
  year={2025}
}
@inproceedings{villar2025playslot,
  title={PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning},
  author={Villar-Corrales, Angel and Behnke, Sven},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@article{li2025worldeval,
  title={WorldEval: World Model as Real-World Robot Policies Evaluator},
  author={Li, Yaxuan and Zhu, Yichen and Wen, Junjie and Shen, Chaomin and Xu, Yi},
  journal={arXiv preprint arXiv:2505.19017},
  year={2025}
}
@article{deng2025graspvla,
  title={Graspvla: a grasping foundation model pre-trained on billion-scale synthetic action data},
  author={Deng, Shengliang and Yan, Mi and Wei, Songlin and Ma, Haixin and Yang, Yuxin and Chen, Jiayi and Zhang, Zhiqi and Yang, Taoyu and Zhang, Xuheng and Cui, Heming},
  journal={arXiv preprint arXiv:2505.03233},
  year={2025}
}
@article{wang2025learning,
  title={Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression},
  author={Wang, Lirui and Zhao, Kevin and Liu, Chaoqi and Chen, Xinlei},
  journal={arXiv preprint arXiv:2502.04296},
  year={2025}
}
@inproceedings{doshi2025scaling,
  title={Scaling Cross-Embodied Learning: One Policy for Manipulation, Navigation, Locomotion and Aviation},
  author={Doshi, Ria and Walke, Homer Rich and Mees, Oier and Dasari, Sudeep and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={496--512},
  year={2025},
  organization={PMLR}
}
@article{team2024octo,
  title={Octo: An open-source generalist robot policy},
  author={Team, Octo Model and Ghosh, Dibya and Walke, Homer and Pertsch, Karl and Black, Kevin and Mees, Oier and Dasari, Sudeep and Hejna, Joey and Kreiman, Tobias and Xu, Charles},
  journal={arXiv preprint arXiv:2405.12213},
  year={2024}
}
@article{wang2024scaling,
  title={Scaling proprioceptive-visual learning with heterogeneous pre-trained transformers},
  author={Wang, Lirui and Chen, Xinlei and Zhao, Jialiang and He, Kaiming},
  journal={Advances in neural information processing systems},
  volume={37},
  pages={124420--124450},
  year={2024}
}

@inproceedings{zhu2025irasim,
  title={Irasim: Learning interactive real-robot action simulators},
  author={Zhu, Fangqi and Wu, Hongtao and Guo, Song and Liu, Yuxiao and Cheang, Chilam and Kong, Tao},
  booktitle={ICCV},
  year={2025}
}
@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}
@article{zhao2024vlmpc,
  title={Vlmpc: Vision-language model predictive control for robotic manipulation},
  author={Zhao, Wentao and Chen, Jiaming and Meng, Ziyu and Mao, Donghui and Song, Ran and Zhang, Wei},
  journal={arXiv preprint arXiv:2407.09829},
  year={2024}
}
@inproceedings{ebert2018robustness,
  title={Robustness via retrying: Closed-loop robotic manipulation with self-supervised learning},
  author={Ebert, Frederik and Dasari, Sudeep and Lee, Alex X and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on robot learning},
  pages={983--993},
  year={2018},
  organization={PMLR}
}

@inproceedings{nair2022learning,
  title={Learning language-conditioned robot behavior from offline data and crowd-sourced annotation},
  author={Nair, Suraj and Mitchell, Eric and Chen, Kevin and Savarese, Silvio and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={1303--1315},
  year={2022},
  organization={PMLR}
}
@article{hu2023look,
  title={Look before you leap: Unveiling the power of gpt-4v in robotic vision-language planning},
  author={Hu, Yingdong and Lin, Fanqi and Zhang, Tong and Yi, Li and Gao, Yang},
  journal={arXiv preprint arXiv:2311.17842},
  year={2023}
}

@inproceedings{dasari2020robonet,
  title={RoboNet: Large-Scale Multi-Robot Learning},
  author={Dasari, Sudeep and Ebert, Frederik and Tian, Stephen and Nair, Suraj and Bucher, Bernadette and Schmeckpeper, Karl and Singh, Siddharth and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={885--897},
  year={2020}
}
@inproceedings{dosovitskiy2017carla,
  title={CARLA: An open urban driving simulator},
  author={Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
  booktitle={Conference on robot learning},
  pages={1--16},
  year={2017}
}
@inproceedings{deitke2020robothor,
  title={Robothor: An open simulation-to-real embodied ai platform},
  author={Deitke, Matt and Han, Winson and Herrasti, Alvaro and Kembhavi, Aniruddha and Kolve, Eric and Mottaghi, Roozbeh and Salvador, Jordi and Schwenk, Dustin and VanderBilt, Eli and Wallingford, Matthew},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3164--3174},
  year={2020}
}

@inproceedings{li2025evaluating,
  title={Evaluating Real-World Robot Manipulation Policies in Simulation},
  author={Li, Xuanlin and Hsu, Kyle and Gu, Jiayuan and Mees, Oier and Pertsch, Karl and Walke, Homer Rich and Fu, Chuyuan and Lunawat, Ishikaa and Sieh, Isabel and Kirmani, Sean},
  booktitle={Conference on Robot Learning},
  pages={3705--3728},
  year={2025},
  organization={PMLR}
}
@inproceedings{xiang2020sapien,
  title={Sapien: A simulated part-based interactive environment},
  author={Xiang, Fanbo and Qin, Yuzhe and Mo, Kaichun and Xia, Yikuan and Zhu, Hao and Liu, Fangchen and Liu, Minghua and Jiang, Hanxiao and Yuan, Yifu and Wang, He},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11097--11107},
  year={2020}
}
@inproceedings{qin2025worldsimbench,
  title={WorldSimBench: Towards Video Generation Models as World Simulators},
  author={Qin, Yiran and Shi, Zhelun and Yu, Jiwen and Wang, Xijun and Zhou, Enshen and Li, Lijun and Yin, Zhenfei and Liu, Xihui and Sheng, Lu and Shao, Jing},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@inproceedings{chen2024rh20t,
  title={RH20T-P: A Primitive-Level Robotic Manipulation Dataset Towards Composable Generalization Agents in Real-world Scenarios},
  author={Chen, Zeren and Shi, Zhelun and Lu, Xiaoya and He, Lehan and Qian, Sucheng and Yin, Zhenfei and Ouyang, Wanli and Shao, Jing and Qiao, Yu and Lu, Cewu},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents},
  year={2024}
}
@inproceedings{yang2025embodiedbench,
  title={EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents},
  author={Yang, Rui and Chen, Hanyang and Zhang, Junyu and Zhao, Mark and Qian, Cheng and Wang, Kangrui and Wang, Qineng and Koripella, Teja Venkat and Movahedi, Marziyeh and Li, Manling},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@article{wang2025dmwm,
  title={DMWM: Dual-Mind World Model with Long-Term Imagination},
  author={Wang, Lingyi and Shelim, Rashed and Saad, Walid and Ramakrishnan, Naren},
  journal={arXiv preprint arXiv:2502.07591},
  year={2025}
}
@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}
@article{yang2025vlipp,
  title={VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior},
  author={Yang, Xindi and Li, Baolu and Zhang, Yiming and Yin, Zhenfei and Bai, Lei and Ma, Liqian and Wang, Zhiyong and Cai, Jianfei and Wong, Tien-Tsin and Lu, Huchuan},
  journal={arXiv preprint arXiv:2503.23368},
  year={2025}
}


@article{yu2025real2render2real,
  title={Real2render2real: Scaling robot data without dynamics simulation or robot hardware},
  author={Yu, Justin and Fu, Letian and Huang, Huang and El-Refai, Karim and Ambrus, Rares Andrei and Cheng, Richard and Irshad, Muhammad Zubair and Goldberg, Ken},
  journal={arXiv preprint arXiv:2505.09601},
  year={2025}
}
@article{escontrela2023video,
  title={Video prediction models as rewards for reinforcement learning},
  author={Escontrela, Alejandro and Adeniji, Ademi and Yan, Wilson and Jain, Ajay and Peng, Xue Bin and Goldberg, Ken and Lee, Youngwoon and Hafner, Danijar and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68760--68783},
  year={2023}
}
@article{liang2025video,
  title={Video Generators are Robot Policies},
  author={Liang, Junbang and Tokmakov, Pavel and Liu, Ruoshi and Sudhakar, Sruthi and Shah, Paarth and Ambrus, Rares and Vondrick, Carl},
  journal={arXiv preprint arXiv:2508.00795},
  year={2025}
}
@incollection{gholami2022survey,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Low-power computer vision},
  pages={291--326},
  year={2022},
  publisher={Chapman and Hall/CRC}
}
@inproceedings{richens2025general,
  title={General agents need world models},
  author={Richens, Jonathan and Everitt, Tom and Abel, David},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@inproceedings{shang2023post,
  title={Post-training quantization on diffusion models},
  author={Shang, Yuzhang and Yuan, Zhihang and Xie, Bin and Wu, Bingzhe and Yan, Yan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1972--1981},
  year={2023}
}
@inproceedings{poursaeed2018generative,
  title={Generative adversarial perturbations},
  author={Poursaeed, Omid and Katsman, Isay and Gao, Bicheng and Belongie, Serge},
  booktitle={CVPR},
  pages={4422--4431},
  year={2018}
}
@inproceedings{huang2019black,
  title={Black-Box Adversarial Attack with Transferable Model-based Embedding},
  author={Huang, Zhichao and Zhang, Tong},
  booktitle={ICLR},
  year={2019}
}
@inproceedings{cojocar2020we,
  title={Are we susceptible to rowhammer? an end-to-end methodology for cloud providers},
  author={Cojocar, Lucian and Kim, Jeremie and Patel, Minesh and Tsai, Lillian and Saroiu, Stefan and Wolman, Alec and Mutlu, Onur},
  booktitle={SP},
  pages={712--728},
  year={2020}
}
@inproceedings{jattke2024zenhammer,
  title={$\{$ZenHammer$\}$: Rowhammer Attacks on $\{$AMD$\}$ Zen-based Platforms},
  author={Jattke, Patrick and Wipfli, Max and Solt, Flavien and Marazzi, Michele and B{\"o}lcskei, Matej and Razavi, Kaveh},
  booktitle={USENIX Security},
  pages={1615--1633},
  year={2024}
}
@inproceedings{ren2023dimension,
  title={Dimension-independent certified neural network watermarks via mollifier smoothing},
  author={Ren, Jiaxiang and Zhou, Yang and Jin, Jiayin and Lyu, Lingjuan and Yan, Da},
  booktitle={ICML},
  pages={28976--29008},
  year={2023},
  organization={PMLR}
}
@inproceedings{park2022blurs,
  title={Blurs behave like ensembles: Spatial smoothings to improve accuracy, uncertainty, and robustness},
  author={Park, Namuk and Kim, Songkuk},
  booktitle={ICML},
  pages={17390--17419},
  year={2022}
}
@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@inproceedings{zhang2024universal,
  title={Universal adversarial perturbations for vision-language pre-trained models},
  author={Zhang, Peng-Fei and Huang, Zi and Bai, Guangdong},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={862--871},
  year={2024}
}
@inproceedings{zhang2021joint,
  title={Joint-teaching: Learning to refine knowledge for resource-constrained unsupervised cross-modal retrieval},
  author={Zhang, Peng-Fei and Duan, Jiasheng and Huang, Zi and Yin, Hongzhi},
  booktitle={Proceedings of the 29th ACM international conference on multimedia},
  pages={1517--1525},
  year={2021}
}
@inproceedings{li2021lightweight,
  title={Lightweight self-attentive sequential recommendation},
  author={Li, Yang and Chen, Tong and Zhang, Peng-Fei and Yin, Hongzhi},
  booktitle={Proceedings of the 30th ACM international conference on information \& knowledge management},
  pages={967--977},
  year={2021}
}
@inproceedings{polino2018model,
  title={Model compression via distillation and quantization},
  author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@article{song2025hume,
  title={Hume: Introducing System-2 Thinking in Visual-Language-Action Model},
  author={Song, Haoming and Qu, Delin and Yao, Yuanqi and Chen, Qizhi and Lv, Qi and Tang, Yiwen and Shi, Modi and Ren, Guanghui and Yao, Maoqing and Zhao, Bin},
  journal={arXiv preprint arXiv:2505.21432},
  year={2025}
}
@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{team2025gemini,
  title={Gemini robotics: Bringing ai into the physical world},
  author={Team, Gemini Robotics and Abeyruwan, Saminda and Ainslie, Joshua and Alayrac, Jean-Baptiste and Arenas, Montserrat Gonzalez and Armstrong, Travis and Balakrishna, Ashwin and Baruch, Robert and Bauza, Maria and Blokzijl, Michiel},
  journal={arXiv preprint arXiv:2503.20020},
  year={2025}
}
@inproceedings{shi2025hi,
  title={Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models},
  author={Shi, Lucy Xiaoyang and Equi, Michael Robert and Ke, Liyiming and Pertsch, Karl and Vuong, Quan and Tanner, James and Walling, Anna and Wang, Haohuan and Fusai, Niccolo and Li-Bell, Adrian},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@inproceedings{wang2025founder,
  title={Founder: Grounding foundation models in world models for open-ended embodied decision making},
  author={Wang, Yucen and Yu, Rui and Wan, Shenghua and Gan, Le and Zhan, De-Chuan},
  booktitle={Forty-second International Conference on Machine Learning},
  year={2025}
}
@article{mazzaglia2024genrl,
  title={GenRL: Multimodal-foundation world models for generalization in embodied agents},
  author={Mazzaglia, Pietro and Verbelen, Tim and Dhoedt, Bart and Courville, Aaron and Rajeswar, Sai},
  journal={Advances in neural information processing systems},
  volume={37},
  pages={27529--27555},
  year={2024}
}
@inproceedings{sekar2020planning,
  title={Planning to explore via self-supervised world models},
  author={Sekar, Ramanan and Rybkin, Oleh and Daniilidis, Kostas and Abbeel, Pieter and Hafner, Danijar and Pathak, Deepak},
  booktitle={International conference on machine learning},
  pages={8583--8592},
  year={2020}
}

@article{gupta2024essential,
  title={The essential role of causality in foundation world models for embodied AI},
  author={Gupta, Tarun and Gong, Wenbo and Ma, Chao and Pawlowski, Nick and Hilmkil, Agrin and Scetbon, Meyer and Rigter, Marc and Famoti, Ade and Llorens, Ashley Juan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.06665},
  year={2024}
}

@article{tomar2021model,
  title={Model-invariant state abstractions for model-based reinforcement learning},
  author={Tomar, Manan and Zhang, Amy and Calandra, Roberto and Taylor, Matthew E and Pineau, Joelle},
  journal={arXiv preprint arXiv:2102.09850},
  year={2021}
}
@article{pearl2019seven,
  title={The seven tools of causal inference, with reflections on machine learning},
  author={Pearl, Judea},
  journal={Communications of the ACM},
  volume={62},
  number={3},
  pages={54--60},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@article{stuart2010matching,
  title={Matching methods for causal inference: A review and a look forward},
  author={Stuart, Elizabeth A},
  journal={Statistical science: a review journal of the Institute of Mathematical Statistics},
  volume={25},
  number={1},
  pages={1},
  year={2010}
}
@article{chernozhukov2018double,
  title={Double/debiased machine learning for treatment and structural parameters},
  author={Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
  journal={The Econometrics Journal},
  pages={C1--C68},
  year={2018},
  publisher={JSTOR}
}

@article{peper2025four,
  title={Four Principles for Physically Interpretable World Models},
  author={Peper, Jordan and Mao, Zhenjiang and Geng, Yuang and Pan, Siyuan and Ruchkin, Ivan},
  journal={arXiv preprint arXiv:2503.02143},
  year={2025}
}
@inproceedings{nottingham2023embodied,
  title={Do embodied agents dream of pixelated sheep: Embodied decision making using language guided world modelling},
  author={Nottingham, Kolby and Ammanabrolu, Prithviraj and Suhr, Alane and Choi, Yejin and Hajishirzi, Hannaneh and Singh, Sameer and Fox, Roy},
  booktitle={International Conference on Machine Learning},
  pages={26311--26325},
  year={2023}
}
@article{xiang2023language,
  title={Language models meet world models: Embodied experiences enhance language models},
  author={Xiang, Jiannan and Tao, Tianhua and Gu, Yi and Shu, Tianmin and Wang, Zirui and Yang, Zichao and Hu, Zhiting},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={75392--75412},
  year={2023}
}
@article{xing2025critiques,
  title={Critiques of World Models},
  author={Xing, Eric and Deng, Mingkai and Hou, Jinyu and Hu, Zhiting},
  journal={arXiv preprint arXiv:2507.05169},
  year={2025}
}
@inproceedings{rigter2025avid,
  title={AVID: Adapting Video Diffusion Models to World Models},
  author={Rigter, Marc and Gupta, Tarun and Hilmkil, Agrin and Ma, Chao},
  booktitle={Reinforcement Learning Conference},
  year={2025}
}
@inproceedings{finn2016unsupervised,
  title={Unsupervised learning for physical interaction through video prediction},
  author={Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={64--72},
  year={2016}
}
@article{bu2025agibot,
  title={Agibot world colosseo: A large-scale manipulation platform for scalable and intelligent embodied systems},
  author={Bu, Qingwen and Cai, Jisong and Chen, Li and Cui, Xiuqi and Ding, Yan and Feng, Siyuan and Gao, Shenyuan and He, Xindong and Hu, Xuan and Huang, Xu},
  journal={arXiv preprint arXiv:2503.06669},
  year={2025}
}
@inproceedings{bansal2025videophy,
  title={VideoPhy: Evaluating Physical Commonsense for Video Generation},
  author={Bansal, Hritik and Lin, Zongyu and Xie, Tianyi and Zong, Zeshun and Yarom, Michal and Bitton, Yonatan and Jiang, Chenfanfu and Sun, Yizhou and Chang, Kai-Wei and Grover, Aditya},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@article{bai2025qwen2,
  title={Qwen2. 5-vl technical report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025}
}
@article{wan2025wan,
  title={Wan: Open and advanced large-scale video generative models},
  author={Wan, Team and Wang, Ang and Ai, Baole and Wen, Bin and Mao, Chaojie and Xie, Chen-Wei and Chen, Di and Yu, Feiwu and Zhao, Haiming and Yang, Jianxiao},
  journal={arXiv preprint arXiv:2503.20314},
  year={2025}
}
@inproceedings{walke2023bridgedata,
  title={Bridgedata v2: A dataset for robot learning at scale},
  author={Walke, Homer Rich and Black, Kevin and Zhao, Tony Z and Vuong, Quan and Zheng, Chongyi and Hansen-Estruch, Philippe and He, Andre Wang and Myers, Vivek and Kim, Moo Jin and Du, Max},
  booktitle={Conference on Robot Learning},
  pages={1723--1736},
  year={2023}
}
@inproceedings{rosete2023latent,
  title={Latent plans for task-agnostic offline reinforcement learning},
  author={Rosete-Beas, Erick and Mees, Oier and Kalweit, Gabriel and Boedecker, Joschka and Burgard, Wolfram},
  booktitle={Conference on Robot Learning},
  pages={1838--1849},
  year={2023}
}
@inproceedings{gu2023maniskill2,
  title={ManiSkill2: A Unified Benchmark for Generalizable Manipulation Skills},
  author={Gu, Jiayuan and Xiang, Fanbo and Li, Xuanlin and Ling, Zhan and Liu, Xiqiang and Mu, Tongzhou and Tang, Yihe and Tao, Stone and Wei, Xinyue and Yao, Yunchao},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
}
@inproceedings{mandlekar2019scaling,
  title={Scaling robot supervision to hundreds of hours with roboturk: Robotic manipulation dataset through human reasoning and dexterity},
  author={Mandlekar, Ajay and Booher, Jonathan and Spero, Max and Tung, Albert and Gupta, Anchit and Zhu, Yuke and Garg, Animesh and Savarese, Silvio and Fei-Fei, Li},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1048--1055},
  year={2019},
  organization={IEEE}
}
@article{mittal2023orbit,
  title={Orbit: A unified simulation framework for interactive robot learning environments},
  author={Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad},
  journal={IEEE Robotics and Automation Letters},
  volume={8},
  number={6},
  pages={3740--3747},
  year={2023},
  publisher={IEEE}
}

@article{brohan2023rt,
  title={RT-1: Robotics Transformer for Real-World Control at Scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alexander and Hsu, Jasmine},
  journal={Robotics: Science and Systems},
  year={2023},
  publisher={Robotics: Science and Systems Foundation}
}
@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent},
  booktitle={Conference on robot learning},
  pages={651--673},
  year={2018}
}
@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2630--2640},
  year={2019}
}
@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4015--4026},
  year={2023}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}
@article{ma2025latte,
  title={Latte: Latent diffusion transformer for video generation},
  author={Ma, Xin and Wang, Yaohui and Chen, Xinyuan and Jia, Gengyun and Liu, Ziwei and Li, Yuan-Fang and Chen, Cunjian and Qiao, Yu},
  journal={Transactions on Machine Learning Research},
  year={2025}
}
@article{mees2022calvin,
  title={Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks},
  author={Mees, Oier and Hermann, Lukas and Rosete-Beas, Erick and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={7327--7334},
  year={2022},
  publisher={IEEE}
}
@inproceedings{chang2017matterport3d,
  title={Matterport3D: Learning from RGB-D Data in Indoor Environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niebner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  booktitle={2017 International Conference on 3D Vision (3DV)},
  pages={667--676},
  year={2017},
  organization={IEEE Computer Society}
}
@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5842--5850},
  year={2017}
}
@inproceedings{damen2018scaling,
  title={Scaling egocentric vision: The epic-kitchens dataset},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={720--736},
  year={2018}
}
@article{carreira2019short,
  title={A short note on the kinetics-700 human action dataset},
  author={Carreira, Joao and Noland, Eric and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.06987},
  year={2019}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robotic motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}
@article{vafa2025has,
  title={What has a foundation model found? using inductive bias to probe for world models},
  author={Vafa, Keyon and Chang, Peter G and Rambachan, Ashesh and Mullainathan, Sendhil},
  journal={arXiv preprint arXiv:2507.06952},
  year={2025}
}
@article{zhou2025vision,
  title={Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge},
  author={Zhou, Zhongyi and Zhu, Yichen and Wen, Junjie and Shen, Chaomin and Xu, Yi},
  journal={arXiv preprint arXiv:2505.21906},
  year={2025}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019}
}
@inproceedings{gumbsch2023learning,
  title={Learning hierarchical world models with adaptive temporal abstractions from discrete latent dynamics},
  author={Gumbsch, Christian and Sajid, Noor and Martius, Georg and Butz, Martin V},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
}

@inproceedings{hafnerdream,
  title={Dream to Control: Learning Behaviors by Latent Imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{hafner2025mastering,
  title={Mastering diverse control tasks through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={Nature},
  pages={1--7},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{hansen2022temporal,
  title={Temporal Difference Learning for Model Predictive Control},
  author={Hansen, Nicklas A and Su, Hao and Wang, Xiaolong},
  booktitle={International Conference on Machine Learning},
  pages={8387--8406},
  year={2022}

}

@inproceedings{hansen2024td,
  title={TD-MPC2: Scalable, Robust World Models for Continuous Control},
  author={Hansen, Nicklas and Su, Hao and Wang, Xiaolong},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}
@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{ye2021mastering,
  title={Mastering atari games with limited data},
  author={Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={25476--25488},
  year={2021}
}

@article{wang2024efficientzero,
  title={Efficientzero v2: Mastering discrete and continuous control with limited data},
  author={Wang, Shengjie and Liu, Shaohuai and Ye, Weirui and You, Jiacheng and Gao, Yang},
  journal={arXiv preprint arXiv:2403.00564},
  year={2024}
}

@inproceedings{seo2022reinforcement,
  title={Reinforcement learning with action-free pre-training from videos},
  author={Seo, Younggyo and Lee, Kimin and James, Stephen L and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={19561--19579},
  year={2022}
}

@article{wu2023pre,
  title={Pre-training contextualized world models with in-the-wild videos for reinforcement learning},
  author={Wu, Jialong and Ma, Haoyu and Deng, Chaoyi and Long, Mingsheng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={39719--39743},
  year={2023}
}

@article{mendonca2023structured,
  title={Structured world models from human videos},
  author={Mendonca, Russell and Bahl, Shikhar and Pathak, Deepak},
  journal={arXiv preprint arXiv:2308.10901},
  year={2023}
}

@inproceedings{zhang2024prelar,
  title={Prelar: World model pre-training with learnable action representation},
  author={Zhang, Lixuan and Kan, Meina and Shan, Shiguang and Chen, Xilin},
  booktitle={European Conference on Computer Vision},
  pages={185--201},
  year={2024},
  organization={Springer}
}
@article{long2025survey,
  title={A Survey: Learning Embodied Intelligence from Physical Simulators and World Models},
  author={Long, Xiaoxiao and Zhao, Qingrui and Zhang, Kaiwen and Zhang, Zihao and Wang, Dingrui and Liu, Yumeng and Shu, Zhengjie and Lu, Yi and Wang, Shouzheng and Wei, Xinzhe},
  journal={arXiv preprint arXiv:2507.00917},
  year={2025}
}
@article{lin2025exploring,
  title={Exploring the evolution of physics cognition in video generation: A survey},
  author={Lin, Minghui and Wang, Xiang and Wang, Yishan and Wang, Shu and Dai, Fengqi and Ding, Pengxiang and Wang, Cunxiang and Zuo, Zhengrong and Sang, Nong and Huang, Siteng},
  journal={arXiv preprint arXiv:2503.21765},
  year={2025}
}
@article{kong20253d,
  title={3D and 4D world modeling: A survey},
  author={Kong, Lingdong and Yang, Wesley and Mei, Jianbiao and Liu, Youquan and Liang, Ao and Zhu, Dekai and Lu, Dongyue and Yin, Wei and Hu, Xiaotao and Jia, Mingkai},
  journal={arXiv preprint arXiv:2509.07996},
  year={2025}
}
@article{ai2025review,
  title={A review of learning-based dynamics models for robotic manipulation},
  author={Ai, Bo and Tian, Stephen and Shi, Haochen and Wang, Yixuan and Pfaff, Tobias and Tan, Cheston and Christensen, Henrik I and Su, Hao and Wu, Jiajun and Li, Yunzhu},
  journal={Science Robotics},
  volume={10},
  number={106},
  pages={eadt1497},
  year={2025},
  publisher={American Association for the Advancement of Science}
}
@article{yu2025survey,
  title={A survey of interactive generative video},
  author={Yu, Jiwen and Qin, Yiran and Che, Haoxuan and Liu, Quande and Wang, Xintao and Wan, Pengfei and Zhang, Di and Gai, Kun and Chen, Hao and Liu, Xihui},
  journal={arXiv preprint arXiv:2504.21853},
  year={2025}
}
@article{zhu2024sora,
  title={Is sora a world simulator? a comprehensive survey on general world models and beyond},
  author={Zhu, Zheng and Wang, Xiaofeng and Zhao, Wangbo and Min, Chen and Deng, Nianchen and Dou, Min and Wang, Yuqi and Shi, Botian and Wang, Kai and Zhang, Chi},
  journal={arXiv preprint arXiv:2405.03520},
  year={2024}
}
@article{liang2025large,
  title={Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning},
  author={Liang, Wenlong and Zhou, Rui and Ma, Yang and Zhang, Bing and Li, Songlin and Liao, Yijia and Kuang, Ping},
  journal={arXiv preprint arXiv:2508.10399},
  year={2025}
}
@article{ding2025understanding,
  title={Understanding world or predicting future? a comprehensive survey of world models},
  author={Ding, Jingtao and Zhang, Yunke and Shang, Yu and Zhang, Yuheng and Zong, Zefang and Feng, Jie and Yuan, Yuan and Su, Hongyuan and Li, Nian and Sukiennik, Nicholas},
  journal={ACM Computing Surveys},
  volume={58},
  number={3},
  pages={1--38},
  year={2025},
  publisher={ACM New York, NY}
}
@online{physx_docs,
  title        = {NVIDIA PhysX SDK Documentation},
  url          = {https://developer.nvidia.com/physx-sdk},
  author       = {NVIDIA },
}
@online{Gemini_docs,
  title        = {Gemini},
  url          = {https://gemini.google.com/app},
  author       = {Google},
}
@online{nvidia_wm2025,
  title        = {World models},
  url          = {https://www.nvidia.com/en-au/glossary/world-models},
  author       = {NVIDIA},
  year={2025},
}

@inproceedings{assran2023self,
  title={Self-supervised learning from images with a joint-embedding predictive architecture},
  author={Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15619--15629},
  year={2023}
}
@article{bardes2024revisiting,
  title={Revisiting feature prediction for learning visual representations from video},
  author={Bardes, Adrien and Garrido, Quentin and Ponce, Jean and Chen, Xinlei and Rabbat, Michael and LeCun, Yann and Assran, Mahmoud and Ballas, Nicolas},
  journal={arXiv preprint arXiv:2404.08471},
  year={2024}
}
@article{assran2025v,
  title={V-jepa 2: Self-supervised video models enable understanding, prediction and planning},
  author={Assran, Mido and Bardes, Adrien and Fan, David and Garrido, Quentin and Howes, Russell and Muckley, Matthew and Rizvi, Ammar and Roberts, Claire and Sinha, Koustuv and Zholus, Artem},
  journal={arXiv preprint arXiv:2506.09985},
  year={2025}
}
@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={661--668},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}
@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart},
  booktitle={Icml},
  volume={1},
  number={2},
  pages={2},
  year={2000}
}
@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@article{ho2016gail,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{baram2016mail,
  title={Model-based adversarial imitation learning},
  author={Baram, Nir and Anschel, Oron and Mannor, Shie},
  journal={arXiv preprint arXiv:1612.02179},
  year={2016}
}
@article{rafailov2021vmail,
  title={Visual adversarial imitation learning using variational models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3016--3028},
  year={2021}
}
@article{yin2022efficientimitate,
  title={Planning for sample efficient imitation learning},
  author={Yin, Zhao-Heng and Ye, Weirui and Chen, Qifeng and Gao, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2577--2589},
  year={2022}
}
@article{demoss2023ditto,
  title={Ditto: Offline imitation learning with world models},
  author={DeMoss, Branton and Duckworth, Paul and Hawes, Nick and Posner, Ingmar},
  journal={arXiv preprint arXiv:2302.03086},
  year={2023}
}
@inproceedings{zhang2023dmil,
  title={Discriminator-guided model-based offline imitation learning},
  author={Zhang, Wenjia and Xu, Haoran and Niu, Haoyi and Cheng, Peng and Li, Ming and Zhang, Heming and Zhou, Guyue and Zhan, Xianyuan},
  booktitle={Conference on robot learning},
  pages={1266--1276},
  year={2023}
}
@inproceedings{kolev2024cmil,
  title={Efficient imitation learning with conservative world models},
  author={Kolev, Victor and Rafailov, Rafael and Hatch, Kyle and Wu, Jiajun and Finn, Chelsea},
  booktitle={6th Annual Learning for Dynamics \& Control Conference},
  pages={1777--1790},
  year={2024},
  organization={PMLR}
}
@article{li2024reward,
  title={Reward-free World Models for Online Imitation Learning},
  author={Li, Shangzhe and Huang, Zhiao and Su, Hao},
  journal={arXiv preprint arXiv:2410.14081},
  year={2024}
}

@inproceedings{pang2025reviwo,
  title={Learning View-invariant World Models for Visual Robotic Manipulation},
  author={Pang, Jing-Cheng and Tang, Nan and Li, Kaiyuan and Tang, Yuting and Cai, Xin-Qiang and Zhang, Zhen-Yu and Niu, Gang and Sugiyama, Masashi and Yu, Yang},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{martinez2025coral,
  title={In-Context Reinforcement Learning via Communicative World Models},
  author={Martinez-Lopez, Fernando and Li, Tao and Lu, Yingdong and Chen, Juntao},
  journal={arXiv preprint arXiv:2508.06659},
  year={2025}
}
@article{rigter2024polygrad,
  title={World models via policy-guided trajectory diffusion},
  author={Rigter, M and Yamada, J and Posner, I},
  journal={Transactions on Machine Learning Research},
  volume={2024},
  number={2},
  year={2024},
  publisher={Journal of Machine Learning Research}
}
@article{chen2025robohorizon,
  title={Robohorizon: An llm-assisted multi-view world model for long-horizon robotic manipulation},
  author={Chen, Zixuan and Huo, Jing and Chen, Yangtao and Gao, Yang},
  journal={arXiv preprint arXiv:2501.06605},
  year={2025}
}
@article{chen2025vlwm,
  title={Planning with Reasoning using Vision Language World Model},
  author={Chen, Delong and Moutakanni, Theo and Chung, Willy and Bang, Yejin and Ji, Ziwei and Bolourchi, Allen and Fung, Pascale},
  journal={arXiv preprint arXiv:2509.02722},
  year={2025}
}
@article{xiao2025world,
  title={World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training},
  author={Xiao, Junjin and Yang, Yandan and Chang, Xinyuan and Chen, Ronghan and Xiong, Feng and Xu, Mu and Zheng, Wei-Shi and Zhang, Qing},
  journal={arXiv preprint arXiv:2509.24948},
  year={2025}
}